%demo of manual dewy tokenizer written in dewy

% (template) instance of the token class
TokenBase = [
    name = 'Token'
    __repr__ = () => '<{name}>'
]
Token = type(TokenBase)


% class constructor for Keyword token type
Keyword = src:string => [
    ...TokenBase
    name = 'Keyword'
    __repr__ = () => '<{name}: {src}>'
]


eat_fn_type = src:string :> int|void


%{
    Eat a reserved keyword, return the number of characters eaten

    #keyword = {in} | {as} | {loop} | {lazy} | {if} | {and} | {or} | {xor} | {nand} | {nor} | {xnor} | {not}; 

    noting that keywords are case insensitive
}%
eat_keyword = src:string :> int|void => {
    keywords = ['in' 'as' 'loop' 'lazy' 'if' 'and' 'or' 'xor' 'nand' 'nor' 'xnor' 'not']
    max_len = [loop k in keywords k.length].max
    lower_src = src[..max_len].lowercase
    loop k in keywords
        if lower_src.startswith(k)
            return k.length
    return undefined
}
